import com.amazonaws.services.glue.ChoiceOption
import com.amazonaws.services.glue.GlueContext
import com.amazonaws.services.glue.MappingSpec
import com.amazonaws.services.glue.ResolveSpec
import com.amazonaws.services.glue.errors.CallSite
import com.amazonaws.services.glue.util.GlueArgParser
import com.amazonaws.services.glue.util.Job
import com.amazonaws.services.glue.util.JsonOptions
import org.apache.spark.SparkContext
import scala.collection.JavaConverters._
import org.apache.spark.sql.{Row, SQLContext}
import org.apache.spark.sql.types
import org.slf4j.LoggerFactory


import com.amazon.deequ.analyzers.runners.{AnalysisRunner, AnalyzerContext}
import com.amazon.deequ.analyzers.runners.AnalyzerContext.successMetricsAsDataFrame
import com.amazon.deequ.analyzers.{
  Compliance,
  Correlation,
  Size,
  Completeness,
  Mean,
  ApproxCountDistinct
}

object GlueApp {
  def main(sysArgs: Array[String]) {
    val sc: SparkContext = new SparkContext()
    val glueContext: GlueContext = new GlueContext(sc)
    val spark = glueContext.getSparkSession
    val args = GlueArgParser.getResolvedOptions(sysArgs, Seq("JOB_NAME").toArray)
    Job.init(args("JOB_NAME"), glueContext, args.asJava)
    val logger = LoggerFactory.getLogger(args("JOB_NAME"))    
    
    logger.info("Start Job")

    val dataset = spark.read
      .format("csv")
      .option("header", "true")
      .load(
        "s3n://vw-dpp-testdata-chionia/79f27be1-e8fe-4992-a7d5-63164c0c824f.csv"
      )
    val analysisResult: AnalyzerContext = {
      AnalysisRunner
      // data to run the analysis on
        .onData(dataset)
        // define analyzers that compute metrics
        .addAnalyzer(Size())
        .addAnalyzer(Completeness("partnumber"))
        .addAnalyzer(ApproxCountDistinct("partnumber"))
        .addAnalyzer(Mean("programnumber"))
        .addAnalyzer(Compliance("press", "press = 400"))
        .addAnalyzer(Correlation("incompletechecked", "failurefound"))
        .addAnalyzer(Correlation("presscounter", "failurefound"))
        // compute metrics
        .run()
    }

// retrieve successfully computed metrics as a Spark data frame
    val metrics = successMetricsAsDataFrame(spark, analysisResult)
// write metrics result on s3
    metrics.write
      .option("header", "true")
      .mode("overwrite")
      .csv("s3n://vw-dpp-testdata-chionia/metricsresult.csv")

  }
}
